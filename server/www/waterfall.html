<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">
<head>
    <title>Loading and playing a sound with the Web Audio API</title>
    <script src="js/lib/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="js/lib/chroma.js"></script>
    <script src="js/lib/resampler.js"></script>
    <style>
        * {
            font-family: sans-serif;
        }
    </style>
</head>
<body style="background-color: white;">

<canvas id="canvas" width="1024" height="256" style="display: block; background-color: black ;"></canvas>

<script type="text/javascript">

    // create the audio context (chrome only for now)
    if (! window.AudioContext) {
        if (! window.webkitAudioContext) {
            alert('no audiocontext found');
        }
        window.AudioContext = window.webkitAudioContext;
    }
    
    // Get the microphone input
    function getUserMedia(dictionary, callback) {
        try {
            navigator.webkitGetUserMedia(dictionary, callback, onError);
        } catch (e) {
            alert('webkitGetUserMedia threw exception :' + e);
        }
    }
    
    var scriptNodes = {};
    var keep = (function () {
        var nextNodeID = 1;
        return function (node) {
            node.id = node.id || (nextNodeID++);
            scriptNodes[node.id] = node;
            return node;
        };
    }());
    
    function drop(node) {
        delete scriptNodes[node.id];
        return node;
    }
    
    // Events
    // init() once the page has finished loading.
    window.onload = init;

    var context;

    var audioBuffer;
    var sourceNode;
    var analyser;
    var javascriptNode;

    // get the context from the canvas to draw on
    var ctx = $("#canvas").get()[0].getContext("2d");

    // create a temp canvas we use for copying
    var tempCanvas = document.createElement("canvas"),
        tempCtx = tempCanvas.getContext("2d");
    tempCanvas.width=1024;
    tempCanvas.height=256;

    // used for color distribution
    var hot = new chroma.ColorScale({
        //colors: ['#5C4D6B', '#536887', '#3D839A', '#259FA1', '#35B89B', '#67CF8A', '#A3E275', '#E7F065' ],
        //colors: ['#5C4D6B', '#3F627B', '#1C757A', '#2A8569', '#5B8F4F', '#91933B', '#C89140', '#F78B65' ],
        colors: [ '#000000', '#0B16B5', '#FFF782', '#EB1250' ],
        
        // colors:['#000000', '#ff0000', '#ffff00', '#ffffff'],
        // positions:[0, .125, 0.25, 0.375, 0.5, 0.625, 0.75, 1],
        positions: [ 0, 0.4, 0.68, 0.85 ],
        mode:'rgb',
        limits:[0, 300]
    });
    
    // Open the microphone
    function init() {
        var audioConstraints = {
            audio: true
        };
        getUserMedia(audioConstraints, gotStream);
    }

    // Called once we get a live audio stream of user input
    function gotStream(stream) {
        initAudio(stream);
    }
    

    function initAudio(stream) {
        context = new AudioContext();
        //context = new webkitOfflineAudioContext(1,8192,44100);

        
        // Create an AudioNode from the stream (live input)
        var sourceNode = context.createMediaStreamSource(stream);
        
        // Filter the audio to limit bandwidth to 4kHz before resampling,
        // by using a BiQuadFilterNode:
        var filterNode = context.createBiquadFilter();
        filterNode.type = filterNode.LOWPASS; // Low pass
        filterNode.frequency.value = 3800;
        filterNode.Q.value = 1.5;
        filterNode.gain.value = 0;
        
        sourceNode.connect(filterNode);
        sourceNode.connect(context.destination);
        

        // Create an audio resampler:
        var resamplerNode = keep(context.createScriptProcessor(8192,1,1));
        resamplerNode.onaudioprocess = (function() {
            // We're getting a 4500Hz bandwidth which is enough for the bandwidth
            // of the audio of our receiver (4kHz max).
            //
            // The output data will be 1638 or 1939 samples long (8192 samples divided by 5)
            var rss  = new Resampler(44100, 8820, 1, 1639, true);
            //var ring = new Float32Array(8192);
            //var idx = 0;
            return function(event) {
                var inp, out;
                //console.log(event);
                inp = event.inputBuffer.getChannelData(0);
                out = event.outputBuffer.getChannelData(0);
                var l = rss.resampler(inp);
                // the "out" variable is a reference to a Float32Array.
                // We can edit the values of the array, but not change the reference -
                // if we do, it won't do anything, the audioBuffer will keep its internal
                // reference: therefore we need to manually copy all samples:
                for (var i=0; i < l; ++i) {
                    // ring[(i+idx)%8192] = rss.outputBuffer[i];
                    out[i] = rss.outputBuffer[i];
                }
                // Now copy the ring buffer to the output channel
                //for (var i=0; i < 8192; ++i) {
                //    out[i] = ring[(idx+i)%8192];
                //}
                //idx = (idx+l)%8192;    
                //requestAnimationFrame(drawSpectrogram);
            };
        }());

        filterNode.connect(resamplerNode);
                
        // Create an audio analyser:
        analyser = context.createAnalyser();
        analyser.smoothingTimeConstant = 0;
        analyser.fftSize = 2048;

        // Then connect the analyser to the resampler node
        // The issue here is, that the analyser is going to get input
        // buffers that are only filled up to 1639 samples, the rest being
        // silence, since we have a sample rate mismatch after the resampler node.
        resamplerNode.connect(analyser);
        
        //requestAnimationFrame(drawSpectrogram);
        
        var syncDisplay  = keep(context.createScriptProcessor(2048,1,1));
        syncDisplay.onaudioprocess = function() {
            // get the average for the first channel
            var array = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(array);
            drawSpectrogram(array);
        }
        
        syncDisplay.connect(context.destination);
        
        //analyser.connect(context.destination);

    }

    // log if an error occurs
    function onError(e) {
        console.log(e);
    }

    function drawSpectrogram(array) {

        // The analyzer is in constant underrun because it assumes
        // we have a 44.1kHz sample rate, and we downsampled 5 times to
        // 8820. 
        
        // The only way, very empirical, is to check if we have a zero
        // frequency in the middle of the band (impossible on a real world
        // system) and skip if it's the case.
        var pwr = 0;
        for (var i=0; i < 1024; i++) {
            pwr += array[i];
        }
        // console.log(pwr);
        if (!pwr) {
            //requestAnimationFrame(drawSpectrogram);
            return;
        }

        // copy the current canvas onto the temp canvas
        var canvas = document.getElementById("canvas");

        tempCtx.drawImage(canvas, 0, 0, 1024, 256);

        // Each pixel is 4500/1024 = 4.39Hz wide
        // iterate over the elements from the array
        for (var i = 0; i < array.length; i++) {
            // draw each pixel with the specific color
            var value = array[i];
            ctx.fillStyle = hot.getColor(value).hex();

            // draw the line at the right side of the canvas
            ctx.fillRect(i, 1, 1, 2);
        }

        // set translate on the canvas
        ctx.translate(0, 2);
        // draw the copied image
        ctx.drawImage(tempCanvas, 0, 0, 1024, 256, 0, 0, 1024, 256);

        // reset the transformation matrix
        ctx.setTransform(1, 0, 0, 1, 0, 0);
        //requestAnimationFrame(drawSpectrogram);

    }

</script>

</body>
</html>